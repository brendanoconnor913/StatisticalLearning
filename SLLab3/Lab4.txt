2.
a)
> summary(Weekly)
      Year           Lag1               Lag2         
 Min.   :1990   Min.   :-18.1950   Min.   :-18.1950  
 1st Qu.:1995   1st Qu.: -1.1540   1st Qu.: -1.1540  
 Median :2000   Median :  0.2410   Median :  0.2410  
 Mean   :2000   Mean   :  0.1506   Mean   :  0.1511  
 3rd Qu.:2005   3rd Qu.:  1.4050   3rd Qu.:  1.4090  
 Max.   :2010   Max.   : 12.0260   Max.   : 12.0260  
      Lag3               Lag4               Lag5         
 Min.   :-18.1950   Min.   :-18.1950   Min.   :-18.1950  
 1st Qu.: -1.1580   1st Qu.: -1.1580   1st Qu.: -1.1660  
 Median :  0.2410   Median :  0.2380   Median :  0.2340  
 Mean   :  0.1472   Mean   :  0.1458   Mean   :  0.1399  
 3rd Qu.:  1.4090   3rd Qu.:  1.4090   3rd Qu.:  1.4050  
 Max.   : 12.0260   Max.   : 12.0260   Max.   : 12.0260  
     Volume            Today          Direction 
 Min.   :0.08747   Min.   :-18.1950   Down:484  
 1st Qu.:0.33202   1st Qu.: -1.1540   Up  :605  
 Median :1.00268   Median :  0.2410             
 Mean   :1.57462   Mean   :  0.1499             
 3rd Qu.:2.05373   3rd Qu.:  1.4050             
 Max.   :9.32821   Max.   : 12.0260    

In looking at the scatter matrix there doesn't seem to be any clear pattern on the classes.

b)

Call:
glm(formula = Direction ~ . - Today - Year, family = binomial, 
    data = Weekly)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.6949  -1.2565   0.9913   1.0849   1.4579  

Coefficients:
            Estimate Std. Error z value Pr(>|z|)   
(Intercept)  0.26686    0.08593   3.106   0.0019 **
Lag1        -0.04127    0.02641  -1.563   0.1181   
Lag2         0.05844    0.02686   2.175   0.0296 * 
Lag3        -0.01606    0.02666  -0.602   0.5469   
Lag4        -0.02779    0.02646  -1.050   0.2937   
Lag5        -0.01447    0.02638  -0.549   0.5833   
Volume      -0.02274    0.03690  -0.616   0.5377   
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1496.2  on 1088  degrees of freedom
Residual deviance: 1486.4  on 1082  degrees of freedom
AIC: 1500.4

Number of Fisher Scoring iterations: 4

None of the predictors seem to be significant. The best case is Lag2 but even that is suspect.

c)

> table(glm.pred,Direction)
        Direction
glm.pred Down  Up
    Down   54  48
    Up    430 557

> mean(glm.pred==Direction)
[1] 0.5610652

We see from the mean that it does a little bit better than random but we do have to consider
that we used all of the data for training so likely is due to overfitting. The confusion matrix
has the majority of the predictions being predicted as up. This means our classifier seems to
have a bias towards the Up Direction.

d)

> table(glm.pred, Weekly[!trainperiod,]$Direction)
glm.pred Down Up
    Down    9  5
    Up     34 56
> mean(glm.pred==Weekly[!trainperiod,]$Direction)
[1] 0.625

e)

> table(lda.pred$class, alttesting$Direction)
      
       Down Up
  Down    9  5
  Up     34 56
> mean(lda.pred$class == alttesting$Direction)
[1] 0.625

f)

> table(qda.pred$class, alttesting$Direction)
      
       Down Up
  Down    0  0
  Up     43 61
> mean(qda.pred$class == alttesting$Direction)
[1] 0.5865385

g)

> table(knn.pred, Direction[!trainperiod])
        
knn.pred Down Up
    Down   21 30
    Up     22 31
> mean(knn.pred == Direction[!trainperiod])
[1] 0.5

h)
It appears that the top performers are the logisitic regression and LDA have the highest accuracy
with 62.5% accuracy.
i)
It doesn't seem like adding different features or adjusting the size of K have done much to 
improve our best results (although increasing K did increase the results for knn). 

3.
b)
It appears that displacement, weight and horsepower have a correlation
with mpg01 whereas the others do not. 
d)
> table(lda.pred$class, newautotest$mpg01)
   
      0   1
  0  59  16
  1   7 115
> mean(lda.pred$class == newautotest$mpg01)
[1] 0.8832487
The test error rate is ~12%.
e)
> table(qda.pred$class, newautotest$mpg01)
   
      0   1
  0  63  23
  1   3 108
> mean(qda.pred$class == newautotest$mpg01)
[1] 0.8680203
The test error rate is ~14%.

f)
> table(glm.pred, newautotest$mpg01)
        
glm.pred  0  1
       0 63 36
       1  3 95
> mean(glm.pred == newautotest$mpg01)
[1] 0.8020305
The test error rate is ~20%.

g)
> table(knn.pred,newautotest$mpg01)
        
knn.pred   0   1
       0  62  29
       1   4 102
> mean(knn.pred == newautotest$mpg01)
[1] 0.8324873
The test error is ~17% for k = 1,
                  ~15% for k = 5,
                  ~15% for k = 10.
It appears k=1 the most flexible model performs best.

4.
LDA:
> table(lda.pred$class, bostest$crim01)
   
      0   1
  0  79  34
  1  11 129
> mean(lda.pred$class == bostest$crim01)
[1] 0.8221344

LOG:
> table(glm.pred, bostest$crim01)
        
glm.pred   0   1
       0  75  16
       1  15 147
> mean(glm.pred == bostest$crim01)
[1] 0.8774704

KNN:
K = 1
> table(knn.pred,bostest$crim01)
        
knn.pred  0  1
       0 81 67
       1  9 96
> mean(knn.pred == bostest$crim01)
[1] 0.6996047

K = 5
> table(knn.pred,bostest$crim01)
        
knn.pred  0  1
       0 86 69
       1  4 94
> mean(knn.pred == bostest$crim01)
[1] 0.7114625

K = 10
> table(knn.pred,bostest$crim01)
        
knn.pred  0  1
       0 85 75
       1  5 88
> mean(knn.pred == bostest$crim01)
[1] 0.6837945

It appears that the log classifier performed the best at 87% success rate.
LDA also performed substaintially better than KNN. It appears that the 
more flexible the model the worse it performed. This may be due to a 
lack of data across the predictors.
